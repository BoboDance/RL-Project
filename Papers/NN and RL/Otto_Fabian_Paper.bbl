\begin{thebibliography}{10}
\providecommand{\url}[1]{{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{DOI~\discretionary{}{}{}#1}\else
  \providecommand{\doi}{DOI~\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi

\bibitem{Abdolmaleki2018}
Abdolmaleki, A., Springenberg, J.T., Tassa, Y., et~al.: {Maximum a Posteriori
  Policy Optimisation}  (2018).
\newblock \urlprefix\url{http://arxiv.org/abs/1806.06920}

\bibitem{Babaeizadeh2017}
Babaeizadeh, M., Frosio, I., Tyree, S., et~al.: {Reinforcement Learning through
  Asynchronous Advantage Actor-Critic on a GPU}  (2017).
\newblock \urlprefix\url{http://arxiv.org/abs/1611.06256}

\bibitem{Barth-Maron2018}
Barth-Maron, G., Hoffman, M.W., Budden, D., et~al.: {Distributed Distributional
  Deterministic Policy Gradients}.
\newblock In: International Conference on Learning Representations (2018).
\newblock \urlprefix\url{http://arxiv.org/abs/1804.08617}

\bibitem{Bellemare2017}
Bellemare, M.G., Dabney, W., Munos, R.: {A Distributional Perspective on
  Reinforcement Learning}.
\newblock In: International Conference for Machine Learning (ICML) (2017).
\newblock \urlprefix\url{http://arxiv.org/abs/1707.06887}

\bibitem{Bellemare2013}
Bellemare, M.G., Naddaf, Y., Veness, J., et~al.: {The Arcade Learning
  Environment: An Evaluation Platform for General Agents}.
\newblock Journal of Artificial Intelligence Research \textbf{47}, 253--279
  (2013).
\newblock \doi{10.1613/jair.3912}.
\newblock \urlprefix\url{http://arxiv.org/abs/1207.4708}

\bibitem{Fujimoto2018}
Fujimoto, S., van Hoof, H., Meger, D.: {Addressing Function Approximation Error
  in Actor-Critic Methods}.
\newblock In: International Conference for Machine Learning (2018).
\newblock \urlprefix\url{http://arxiv.org/abs/1802.09477}

\bibitem{Grosse2016}
Grosse, R., Martens, J.: {A Kronecker-factored Approximate Fisher Matrix for
  Convolution Layers}.
\newblock In: Proceedings of the 33rd International Conference on International
  Conference on Machine Learning - Volume 48, ICML'16, pp. 573--582. JMLR.org
  (2016).
\newblock \urlprefix\url{http://dl.acm.org/citation.cfm?id=3045390.3045452}

\bibitem{Gu2016}
Gu, S., Lillicrap, T., Sutskever, I., et~al.: {Continuous Deep Q-Learning with
  Model-based Acceleration}.
\newblock In: ICML'16 Proceedings of the 33rd International Conference on
  International Conference onMachine Learning - Volume 48, pp. 2829--2838.
  JMLR.org, New York, NY, USA (2016).
\newblock \urlprefix\url{http://arxiv.org/abs/1603.00748}

\bibitem{Haarnoja2018}
Haarnoja, T., Zhou, A., Hartikainen, K., et~al.: {Soft Actor-Critic Algorithms
  and Applications}  (2018).
\newblock \urlprefix\url{http://arxiv.org/abs/1812.05905}

\bibitem{VanHasselt2010}
van Hasselt, H.: {Double Q-learning}.
\newblock In: Advances in Neural Information Processing Systems 23, pp.
  2613--2621. Curran Associates, Inc. (2010).
\newblock
  \urlprefix\url{http://papers.nips.cc/paper/3964-double-q-learning.pdf}

\bibitem{VanHasselt2016}
van Hasselt, H., Guez, A., Silver, D.: {Deep Reinforcement Learning with Double
  Q-learning}.
\newblock In: AAAI Conference on Artificial Intelligence, pp. 2094--2100.
  Phoenix, Arizona (2016).
\newblock \urlprefix\url{http://arxiv.org/abs/1509.06461}

\bibitem{Heess2017}
Heess, N., TB, D., Sriram, S., et~al.: {Emergence of Locomotion Behaviours in
  Rich Environments}  (2017).
\newblock \urlprefix\url{http://arxiv.org/abs/1707.02286}

\bibitem{Hunter2004}
Hunter, D.R., Lange, K.: {A tutorial on MM algorithms}.
\newblock The American Statistician \textbf{58}(1), 30--37 (2004)

\bibitem{Ioffe2015}
Ioffe, S., Szegedy, C.: {Batch Normalization: Accelerating Deep Network
  Training by Reducing Internal Covariate Shift}.
\newblock In: International Conference on Machine Learning (ICML), ICML'15, pp.
  448--456. JMLR.org (2015).
\newblock \urlprefix\url{http://dl.acm.org/citation.cfm?id=3045118.3045167}

\bibitem{Jouppi2017}
Jouppi, N.P., Young, C., Patil, N., et~al.: {In-Datacenter Performance Analysis
  of a Tensor Processing Unit}.
\newblock In: International Symposium on Computer Architecture (ISCA), ISCA
  '17, pp. 1--12. ACM, New York, NY, USA (2017).
\newblock \doi{10.1145/3079856.3080246}.
\newblock \urlprefix\url{http://doi.acm.org/10.1145/3079856.3080246}

\bibitem{Kakade2001}
Kakade, S.: {A Natural Policy Gradient}.
\newblock In: Proceedings of the 14th International Conference on Neural
  Information Processing Systems: Natural and Synthetic, NIPS'01, pp.
  1531--1538. MIT Press, Cambridge, MA, USA (2001).
\newblock \urlprefix\url{http://dl.acm.org/citation.cfm?id=2980539.2980738}

\bibitem{Kulkarni2016}
Kulkarni, T.D., Narasimhan, K., Saeedi, A., et~al.: {Hierarchical Deep
  Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic
  Motivation}.
\newblock In: Advances in Neural Information Processing Systems 29, pp.
  3675--3683. Curran Associates, Inc. (2016).
\newblock
  \urlprefix\url{http://papers.nips.cc/paper/6233-hierarchical-deep-reinforcement-learning-integrating-temporal-abstraction-and-intrinsic-motivation.pdf}

\bibitem{Lillicrap2016}
Lillicrap, T.P., Hunt, J.J., Pritzel, A., et~al.: {Continuous control with deep
  reinforcement learning}.
\newblock In: International Conference on Learning Representations (ICLR) 2016.
  London, UK (2016).
\newblock \urlprefix\url{http://arxiv.org/abs/1509.02971}

\bibitem{Lin1992}
Lin, L.J.: {Self-improving reactive agents based on reinforcement learning,
  planning and teaching}.
\newblock Machine Learning \textbf{8}(3), 293--321 (1992).
\newblock \doi{10.1007/BF00992699}.
\newblock \urlprefix\url{https://doi.org/10.1007/BF00992699}

\bibitem{Lowe2017}
Lowe, R., WU, Y.I., Tamar, A., et~al.: {Multi-Agent Actor-Critic for Mixed
  Cooperative-Competitive Environments}.
\newblock In: Conference on Neural Information Processing Systems (NIPS), pp.
  6379--6390. Curran Associates, Inc., Long Beach, CA, USA (2017).
\newblock
  \urlprefix\url{http://papers.nips.cc/paper/7217-multi-agent-actor-critic-for-mixed-cooperative-competitive-environments.pdf}

\bibitem{Martens2015}
Martens, J., Grosse, R.: {Optimizing Neural Networks with Kronecker-factored
  Approximate Curvature}  (2015).
\newblock \urlprefix\url{http://arxiv.org/abs/1503.05671}

\bibitem{Mnih2016}
Mnih, V., Badia, A.P.A.P., Mirza, M., et~al.: {Asynchronous Methods for Deep
  Reinforcement Learning}.
\newblock In: Proceedings of The 33rd International Conference on Machine
  Learning, \emph{Proceedings of Machine Learning Research}, vol.~48, pp.
  1928--1937. PMLR, New York, New York, USA (2016).
\newblock \urlprefix\url{http://proceedings.mlr.press/v48/mniha16.html
  http://arxiv.org/abs/1602.01783}

\bibitem{Mnih2013}
Mnih, V., Kavukcuoglu, K., Silver, D., et~al.: {Playing Atari with Deep
  Reinforcement Learning}.
\newblock NIPS Deep Learning Workshop 2013  (2013).
\newblock \urlprefix\url{http://arxiv.org/abs/1312.5602}

\bibitem{Mnih2015}
Mnih, V., Kavukcuoglu, K., Silver, D., et~al.: {Human-level control through
  deep reinforcement learning}.
\newblock Nature \textbf{518}(7540), 529--533 (2015).
\newblock \doi{10.1038/nature14236}.
\newblock \urlprefix\url{http://www.nature.com/articles/nature14236}

\bibitem{Munos2016}
Munos, R., Stepleton, T., Harutyunyan, A., et~al.: {Safe and Efficient
  Off-Policy Reinforcement Learning}.
\newblock In: Advances in Neural Information Processing Systems 29, pp.
  1054--1062. Curran Associates, Inc. (2016).
\newblock
  \urlprefix\url{http://papers.nips.cc/paper/6538-safe-and-efficient-off-policy-reinforcement-learning.pdf}

\bibitem{Peters2008a}
Peters, J., Schaal, S.: {Natural actor-critic}.
\newblock Neurocomputing \textbf{71}(7-9), 1180--1190 (2008)

\bibitem{Riedmiller2005}
Riedmiller, M.: {Neural Fitted Q Iteration - First Experiences with a Data
  Efficient Neural Reinforcement Learning Method}.
\newblock In: Machine Learning: ECML 2005, pp. 317--328. Springer Berlin
  Heidelberg, Berlin, Heidelberg (2005)

\bibitem{Riedmiller1993}
Riedmiller, M., Braun, H.: {A Direct Adaptive Method for Faster Backpropagation
  Learning: The RPROP Algorithm}.
\newblock In: IEEE International Conference on Neural Networks (IJCNN), pp.
  586--591 (1993)

\bibitem{Schaul2015}
Schaul, T., Quan, J., Antonoglou, I., et~al.: {Prioritized Experience Replay}.
\newblock In: Interantional Conference for Learning Representations (ICLR)
  (2015).
\newblock \urlprefix\url{http://arxiv.org/abs/1511.05952}

\bibitem{Schulman2015}
Schulman, J., Levine, S., Abbeel, P., et~al.: {Trust Region Policy
  Optimization}.
\newblock In: Proc. 32nd Int. Conf. Mach. Learn., \emph{Proceedings of Machine
  Learning Research}, vol.~37, pp. 1889--1897. PMLR, Lille, France (2015).
\newblock \urlprefix\url{http://proceedings.mlr.press/v37/schulman15.html}

\bibitem{Schulman2017}
Schulman, J., Wolski, F., Dhariwal, P., et~al.: {Proximal Policy Optimization
  Algorithms}  (2017).
\newblock \urlprefix\url{http://arxiv.org/abs/1707.06347}

\bibitem{VanSeijen2009}
van Seijen, H., van Hasselt, H., Whiteson, S., et~al.: {A theoretical and
  empirical analysis of Expected Sarsa}.
\newblock In: 2009 IEEE Symposium on Adaptive Dynamic Programming and
  Reinforcement Learning, pp. 177--184 (2009).
\newblock \doi{10.1109/ADPRL.2009.4927542}

\bibitem{Silver2016}
Silver, D., Huang, A., Maddison, C.J., et~al.: {Mastering the game of Go with
  deep neural networks and tree search}.
\newblock Nature \textbf{529}(7587), 484--489 (2016).
\newblock \doi{10.1038/nature16961}.
\newblock \urlprefix\url{http://www.nature.com/articles/nature16961}

\bibitem{Silver2017}
Silver, D., Hubert, T., Schrittwieser, J., et~al.: {Mastering Chess and Shogi
  by Self-Play with a General Reinforcement Learning Algorithm} pp. 1--19
  (2017).
\newblock \doi{10.1002/acn3.501}.
\newblock \urlprefix\url{http://arxiv.org/abs/1712.01815}

\bibitem{Silver2014}
Silver, D., Lever, G., Heess, N., et~al.: {Deterministic Policy Gradient
  Algorithms}.
\newblock In: International Conference on Machine Learning (ICML), ICML'14, pp.
  I--387----I--395. JMLR.org, Beijing, China (2014).
\newblock \urlprefix\url{http://dl.acm.org/citation.cfm?id=3044805.3044850}

\bibitem{Silver2017a}
Silver, D., Schrittwieser, J., Simonyan, K., et~al.: {Mastering the game of Go
  without human knowledge}.
\newblock Nature \textbf{550}(7676), 354--359 (2017).
\newblock \doi{10.1038/nature24270}.
\newblock \urlprefix\url{http://www.nature.com/doifinder/10.1038/nature24270}

\bibitem{Sutton1990}
Sutton, R.S.: {Integrated architectures for learning, planning, reacting based
  on approxmiate dynmaic programming}.
\newblock In: International Conference for Machine Learning (ICML)2, pp.
  216--224 (1990)

\bibitem{Sutton2018}
Sutton, R.S., Barto, A.G.: {Reinforcement learning: An introduction}, second
  edi edn.
\newblock MIT Press, Cambridge, MA (2018).
\newblock \urlprefix\url{http://incompleteideas.net/book/the-book.html}

\bibitem{Tesauro1994}
Tesauro, G.: {TD-Gammon, a Self-Teaching Backgammon Program, Achieves
  Master-Level Play}.
\newblock Applications of Neural Networks \textbf{6}(2), 215--219 (1994).
\newblock \doi{10.1162/neco.1994.6.2.215}.
\newblock \urlprefix\url{https://doi.org/10.1162/neco.1994.6.2.215}

\bibitem{Todorov2005}
Todorov, E., Li, W.: {A generalized iterative LQG method for locally-optimal
  feedback control of constrained nonlinear stochastic systems}.
\newblock In: American Control Conference, pp. 300--306 vol. 1 (2005).
\newblock \doi{10.1109/ACC.2005.1469949}

\bibitem{Wang2017}
Wang, Z., Bapst, V., Heess, N., et~al.: {Sample Efficient Actor-Critic with
  Experience Replay}.
\newblock In: International Conference on Learning Representations (ICLR)
  (2017).
\newblock \urlprefix\url{http://arxiv.org/abs/1611.01224}

\bibitem{Wang2016}
Wang, Z., Schaul, T., Hessel, M., et~al.: {Dueling Network Architectures for
  Deep Reinforcement Learning}.
\newblock In: Proceedings of the 33rd International Conference on International
  Conference on Machine Learning - Volume 48, ICML'16, pp. 1995--2003. JMLR.org
  (2016).
\newblock \urlprefix\url{http://dl.acm.org/citation.cfm?id=3045390.3045601}

\bibitem{Watkins1989}
Watkins, C.J.C.H.: {Learning from delayed rewards}.
\newblock Ph.D. thesis, King's College, Cambridge (1989)

\bibitem{Williams1992}
Williams, R.J.: {Simple statistical gradient-following algorithms for
  connectionist reinforcement learning}.
\newblock Machine Learning \textbf{8}(3), 229--256 (1992).
\newblock \doi{10.1007/BF00992696}.
\newblock \urlprefix\url{https://doi.org/10.1007/BF00992696}

\bibitem{Wu2017}
Wu, Y., Mansimov, E., Grosse, R.B., et~al.: {Scalable trust-region method for
  deep reinforcement learning using Kronecker-factored approximation}.
\newblock In: Advances in Neural Information Processing Systems 30, pp.
  5279--5288. Curran Associates, Inc. (2017).
\newblock
  \urlprefix\url{http://papers.nips.cc/paper/7112-scalable-trust-region-method-for-deep-reinforcement-learning-using-kronecker-factored-approximation.pdf}

\end{thebibliography}
